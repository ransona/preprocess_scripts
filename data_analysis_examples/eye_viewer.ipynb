{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 'adamranson'\n",
    "expID = '2025-04-10_26_TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pickle\n",
    "import os\n",
    "import organise_paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import IPython.display as display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Label, Image as ImageWidget\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import threading\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "animalID, remote_repository_root, processed_root, exp_dir_processed, exp_dir_raw = organise_paths.find_paths(userID, expID)\n",
    "exp_dir_processed_recordings = os.path.join(exp_dir_processed,'recordings')\n",
    "exp_dir_processed_cut = os.path.join(exp_dir_processed,'cut')\n",
    "video_path_left = os.path.join(exp_dir_processed,(expID+'_eye1_left.avi'))\n",
    "video_path_right = os.path.join(exp_dir_processed,(expID+'_eye1_right.avi'))\n",
    "\n",
    "# check if cropped videos are in the processed data directory and if not try to copy from the remote repos\n",
    "# this can be removed in the future \n",
    "if not os.path.isfile(video_path_left):\n",
    "    try:\n",
    "        print('Copying eye videos - is is a one-off not required in future')\n",
    "        shutil.copyfile(os.path.join(exp_dir_raw, (expID+'_eye1_left.avi')),video_path_left)\n",
    "        shutil.copyfile(os.path.join(exp_dir_raw, (expID+'_eye1_right.avi')),video_path_right)\n",
    "        print('Done!')\n",
    "    except:\n",
    "        print('Cropped eye videos not found on server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check pupil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye and pupil fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global left_eyedat\n",
    "with open(os.path.join(exp_dir_processed_recordings,'dlcEyeLeft.pickle'), \"rb\") as file: left_eyedat = pickle.load(file)\n",
    "\n",
    "global right_eyedat\n",
    "with open(os.path.join(exp_dir_processed_recordings,'dlcEyeRight.pickle'), \"rb\") as file: right_eyedat = pickle.load(file)\n",
    "stop_flag = False\n",
    "\n",
    "def overlay_plot(frame,position,eyeDat):\n",
    "    # Check if the eyeDat has been fitted well, if not it contains nans\n",
    "    if np.isnan(eyeDat['x'][position]) or np.isnan(eyeDat['y'][position]) or np.isnan(eyeDat['radius'][position]):\n",
    "        # return frame with nothing plotted on it\n",
    "        return frame\n",
    "\n",
    "    color = (255, 0, 0)  # Red in BGR format\n",
    "    thickness = 2\n",
    "    x = eyeDat['eye_lid_x'][np.newaxis,position,:].T\n",
    "    y = eyeDat['eye_lid_y'][np.newaxis,position,:].T\n",
    "    points = np.concatenate([x,y],axis = 1)\n",
    "    is_closed = False\n",
    "    points = points.reshape((-1, 1, 2))  # Reshape points to the required format\n",
    "    points = points.astype(int)\n",
    "    frame = cv2.polylines(frame, [points], is_closed, color, thickness)\n",
    "\n",
    "    # Draw a blue circle\n",
    "    center = (50, 50)\n",
    "    radius = 30\n",
    "    color = (0, 0, 255)  # Blue in BGR format\n",
    "    thickness = 2\n",
    "    frame = cv2.circle(frame, [eyeDat['x'][position].astype(int),eyeDat['y'][position].astype(int)], eyeDat['radius'][position].astype(int), color, thickness)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# this function is to play a single frame\n",
    "def play_video(position, video_widget_L, video_widget_R):\n",
    "    # update left video\n",
    "    try:\n",
    "        cap_L = cv2.VideoCapture(video_path_left)\n",
    "        cap_L.set(cv2.CAP_PROP_POS_FRAMES, position)\n",
    "        ret, frame = cap_L.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Overlay plot\n",
    "            frame = overlay_plot(frame,position,left_eyedat)\n",
    "            # # Display the frame\n",
    "            img = Image.fromarray(frame)\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format='JPEG')\n",
    "            video_widget_L.value = buffer.getvalue()\n",
    "\n",
    "        # update right video\n",
    "        cap_R = cv2.VideoCapture(video_path_right)\n",
    "        cap_R.set(cv2.CAP_PROP_POS_FRAMES, position)\n",
    "        ret, frame = cap_R.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Overlay plot\n",
    "            frame = overlay_plot(frame,position,right_eyedat)\n",
    "            # # Display the frame\n",
    "            img = Image.fromarray(frame)\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format='JPEG')\n",
    "            video_widget_R.value = buffer.getvalue()\n",
    "    except:\n",
    "        print('Error with overlay')\n",
    "# Get total number of frames in the video\n",
    "cap = cv2.VideoCapture(video_path_left)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cap.release()\n",
    "\n",
    "# Create slider\n",
    "slider = widgets.IntSlider(min=0, max=total_frames-1, step=1, description='Position')\n",
    "\n",
    "# Create play button\n",
    "play_button = Button(description='Play')\n",
    "\n",
    "# Create stop button\n",
    "stop_button = Button(description='Stop')\n",
    "\n",
    "# Create video widget\n",
    "video_widget_L = ImageWidget()\n",
    "video_widget_R = ImageWidget()\n",
    "\n",
    "title1 = Label(\"Left eye\")\n",
    "title2 = Label(\"Right eye\")\n",
    "\n",
    "title1.style.font_size = '25px'\n",
    "title1.layout.justify_content = 'center'\n",
    "title2.style.font_size = '25px'\n",
    "title2.layout.justify_content = 'center'\n",
    "\n",
    "def playback_loop():\n",
    "    global stop_flag\n",
    "    position = slider.value\n",
    "    while ((slider.value + 1) < total_frames) & (stop_flag == False):\n",
    "        # advance slider\n",
    "        slider.value = slider.value + 1\n",
    "        play_video(slider.value, video_widget_L,video_widget_R)\n",
    "        # time.sleep(0.033)\n",
    "\n",
    "def on_play_button_click(_):\n",
    "    global stop_flag\n",
    "    stop_flag = False\n",
    "    playback_thread = threading.Thread(target=playback_loop)\n",
    "    playback_thread.start()\n",
    "\n",
    "def on_stop_button_click(_):\n",
    "    global stop_flag\n",
    "    stop_flag = True\n",
    "\n",
    "def on_slider_change(change):\n",
    "    if change['name'] == 'value':\n",
    "        play_video(change['new'], video_widget_L, video_widget_R)\n",
    "\n",
    "play_button.on_click(on_play_button_click)\n",
    "stop_button.on_click(on_stop_button_click)\n",
    "slider.observe(on_slider_change, names='value')\n",
    "\n",
    "# Create layout\n",
    "layout = HBox([slider, play_button, stop_button])\n",
    "\n",
    "# Create vertical Box layouts for each ImageWidget and title\n",
    "widgets_box1 = VBox([title1, video_widget_L])\n",
    "widgets_box2 = VBox([title2, video_widget_R])\n",
    "\n",
    "# Display ImageWidgets with titles side by side using a horizontal Box layout\n",
    "widgets_box = HBox([widgets_box1, widgets_box2])\n",
    "\n",
    "# Display the controls and video\n",
    "display.display(layout)\n",
    "display.display(widgets_box)\n",
    "\n",
    "# interact_manual(lambda position: play_video(position, video_widget), position=slider)\n",
    "play_video(slider.value,video_widget_L,video_widget_R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupil properties vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(exp_dir_processed_recordings,'dlcEyeLeft.pickle'), \"rb\") as file: left_dlc = pickle.load(file)\n",
    "with open(os.path.join(exp_dir_processed_recordings,'dlcEyeRight.pickle'), \"rb\") as file: right_dlc = pickle.load(file)\n",
    "# Create a 3-row subplot to plot pupil position, radius and velocity\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 10))\n",
    "# Plot data on each subplot\n",
    "axs[0].plot(left_dlc['x']-np.nanmedian(left_dlc['x']), color = 'skyblue')\n",
    "axs[0].plot(left_dlc['y']-np.nanmedian(left_dlc['y']), color = 'navy')\n",
    "axs[0].set_title('Left pupil x (light) and y (dark) position')\n",
    "axs[0].set_xlabel('Frame)')\n",
    "axs[0].set_ylabel('Normalised position (pix)')\n",
    "\n",
    "axs[1].plot(right_dlc['x']-np.nanmedian(right_dlc['x']), color = 'lightcoral')\n",
    "axs[1].plot(right_dlc['y']-np.nanmedian(right_dlc['y']), color = 'maroon')\n",
    "axs[1].set_title('Right pupil x (light) and y (dark) position')\n",
    "axs[1].set_xlabel('Frame)')\n",
    "axs[1].set_ylabel('Normalised position (pix)')\n",
    "\n",
    "axs[2].plot(left_dlc['radius'], color = 'blue')\n",
    "axs[2].plot(right_dlc['radius'], color = 'red')\n",
    "axs[2].set_title('Pupil radius of left (blue) and right (red) eye')\n",
    "axs[2].set_xlabel('Frame')\n",
    "axs[2].set_ylabel('Normalised radius (pix)')\n",
    "\n",
    "axs[3].plot(left_dlc['velocity'], color = 'blue')\n",
    "axs[3].plot(right_dlc['velocity'], color = 'red')\n",
    "axs[3].set_title('Pupil velocity of left (blue) and right (red) eye')\n",
    "axs[3].set_xlabel('Frame')\n",
    "axs[3].set_ylabel('Normalised velocity (pix)')\n",
    "# Add overall title and adjust spacing\n",
    "fig.suptitle('Summary of pupil data')\n",
    "fig.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_eyedat.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
